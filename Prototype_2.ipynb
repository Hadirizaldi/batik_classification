{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ccf86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import time\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ee74b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ebc84",
   "metadata": {},
   "source": [
    "## Datasets dan Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0585bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9be031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find location from training data and test data \n",
    "\n",
    "def Path(location) :\n",
    "    root = os.path.join('data', '*')\n",
    "    root = glob(root)\n",
    "    \n",
    "    if location == \"train_sets\" :\n",
    "        path = root[1]\n",
    "    \n",
    "    elif location == \"test_sets\" :\n",
    "        path = root[0]\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b632467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test_train', 'data/train_sets']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = os.path.join('data', '*')\n",
    "root = glob(root)\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eec5162d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train_sets'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = root[1]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e745ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "crop_size = 128\n",
    "\n",
    "#pipeline data augmentation \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(crop_size, scale=(0.8, 1.0)),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(0, shear=(10)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(135),\n",
    "    transforms.CenterCrop(crop_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cca44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.ImageFolder(Path('train_sets'), transform=train_transform)\n",
    "test_set = datasets.ImageFolder(Path('test_sets'), transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f5730ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_train = len(train_set)\n",
    "# indices = list(range(num_train))\n",
    "# np.random.shuffle(indices)\n",
    "# split = int(np.floor(0.3 * num_train))\n",
    "# train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afc95972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 596\n",
      "    Root location: data/train_sets\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCrop(size=(128, 128), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
      "               RandomVerticalFlip(p=0.5)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               RandomAffine(degrees=[0.0, 0.0], shear=[-10.0, 10.0])\n",
      "               RandomRotation(degrees=[-20.0, 20.0], interpolation=nearest, expand=False, fill=0)\n",
      "               ToTensor()\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 252\n",
      "    Root location: data/test_train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=135, interpolation=bilinear, max_size=None, antialias=None)\n",
      "               CenterCrop(size=(128, 128))\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print (train_set)\n",
    "print (test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d889cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loader, valid_loader, test_loader\n",
    "train_loader = DataLoader(train_set, batch_size=bs, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08dc6bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 128, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature, target = next(iter(train_loader))\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6638f402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beras_kutah',\n",
       " 'gajah_oling',\n",
       " 'gedegan',\n",
       " 'kopi_pecah',\n",
       " 'moto_pitik',\n",
       " 'paras_gempal',\n",
       " 'sisikan']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2cat = train_set.classes\n",
    "label2cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63de237",
   "metadata": {},
   "source": [
    "## model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d18f7d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_model(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=7),\n",
    "            nn.LogSoftmax(1)\n",
    "        )\n",
    "    def forward(self, x) :\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52ba33",
   "metadata": {},
   "source": [
    "## Training preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "989e24d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85b0eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "model = My_model().to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr= lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7ecbe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function looping\n",
    "def looping(mode, dataset, dataloader, model, criterion, optimizer, device) :\n",
    "    if mode ==\"train\" :\n",
    "        model.train()\n",
    "    \n",
    "    elif mode ==\"test\" :\n",
    "        model.eval()\n",
    "    \n",
    "    cost = correct = 0\n",
    "    for feature, target in tqdm(dataloader, desc=mode.title()) :\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "        output = model(feature)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        if mode ==\"train\" :\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        cost += loss.item() * feature.shape[0]\n",
    "        correct += (output.argmax(1) == target).sum().item()\n",
    "        \n",
    "    cost = cost / len(dataset)\n",
    "    acc = correct / len(dataset)\n",
    "    \n",
    "    return cost, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ff8a08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-679e48550211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msince\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# training for data train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlooping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "epochs = 12\n",
    "train_cost, test_cost = [], []\n",
    "train_acc, test_acc = [], []\n",
    "for i in range (epochs) :\n",
    "    since = time.time()\n",
    "    # training for data train\n",
    "    cost, acc = looping(\"train\", train_set, train_loader, model, criterion, optimizer, device)\n",
    "    train_cost.append(cost)\n",
    "    train_acc.append(acc)\n",
    "    \n",
    "    # training for data val\n",
    "    with torch.no_grad() :\n",
    "        cost, acc = looping(\"test\", test_set, test_loader, model, criterion, optimizer, device)\n",
    "        test_cost.append(cost)\n",
    "        test_acc.append(acc)\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch: {i+1}/{epochs} | train_cost : {train_cost[-1]} | test_cost : {test_cost[-1]} | \"\n",
    "         f\"train_acc: {train_acc[-1]} | test_acc : {test_acc[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7333d902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598eac0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
